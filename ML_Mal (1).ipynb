{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6r9ATFJImOU"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/sec6/\n",
        "%ls -a\n",
        "!pip install pytorch-gradcam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yiJqezNTcuR8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "import os\n",
        "import scipy\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import glob\n",
        "\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "from torchvision import models\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms as transforms\n",
        "\n",
        "from gradcam.utils import visualize_cam\n",
        "from gradcam import GradCAM, GradCAMpp\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "reVMpcBzc1Rq"
      },
      "outputs": [],
      "source": [
        "path = \"/content/drive/MyDrive/sec6\"\n",
        "im_fd = \"/cell_images/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSP5x0KFalul"
      },
      "outputs": [],
      "source": [
        "folder = ['Uninfected','Parasitized']\n",
        "file0 = glob.glob(path + im_fd + folder[0] +\"/*.png\")[0]\n",
        "print(file0)\n",
        "image = Image.open(file0)\n",
        "plt.imshow(image)\n",
        "np.array(image)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")\n",
        "image_size = 128;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7IUjJAiiqz8"
      },
      "outputs": [],
      "source": [
        "SEED = 42\n",
        "\n",
        "def seed_fix(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.use_deterministic_algorithms = True\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "\n",
        "seed_fix(SEED)\n",
        "generator = torch.Generator()\n",
        "generator.manual_seed(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74olKl2cdoF6"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import random\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "folder = ['Uninfected', 'Parasitized']\n",
        "X, y = [], []\n",
        "usenumber = 1000\n",
        "\n",
        "\n",
        "for i, folname in enumerate(folder):\n",
        "    files = glob.glob(f\"{path + im_fd + folname}/*.png\")\n",
        "    sampled_files = random.sample(files, usenumber)\n",
        "\n",
        "\n",
        "    for file in tqdm(sampled_files, desc=f\"Processing {folname}\"):\n",
        "        image = Image.open(file).convert(\"RGB\").resize((image_size, image_size))\n",
        "        data = np.asarray(image)\n",
        "        X.append(data)\n",
        "        y.append(i)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Su2AkQLWb3CR"
      },
      "outputs": [],
      "source": [
        "\n",
        "X = np.array(X).astype(np.float32).transpose(0,3,1,2)/255\n",
        "y = np.array(y)\n",
        "Nall = X.shape[0]\n",
        "tensor_X = torch.tensor(X, dtype=torch.float32)\n",
        "tensor_y = torch.tensor(y, dtype=torch.int64)\n",
        "dataset = torch.utils.data.TensorDataset(tensor_X,tensor_y)\n",
        "n_train = int(Nall * 0.7)\n",
        "n_val = int(Nall * 0.2)\n",
        "n_test = Nall - n_train - n_val\n",
        "train_x, val_x, test_x = torch.utils.data.random_split(dataset, [n_train, n_val,n_test])\n",
        "print(\"train =\",n_train,\",validation =\",n_val,\",Test =\",n_test)\n",
        "batch_size = 64\n",
        "train_dataloader = DataLoader(train_x, batch_size=batch_size, shuffle=True)\n",
        "val_dataloader   = DataLoader(val_x,   batch_size=batch_size, shuffle=False)\n",
        "test_dataloader  = DataLoader(test_x,  batch_size=1, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SEzkL39kWP09"
      },
      "outputs": [],
      "source": [
        "Nall = X.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGUUV3AvX-Lt"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, input_shape=(3,128,128),output_size=2):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Sequential(nn.Conv2d(in_channels=input_shape[0], out_channels=16, kernel_size=3, padding='same'),nn.ReLU(),nn.MaxPool2d(2,2))\n",
        "        self.conv2 = nn.Sequential(nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, padding='same'),nn.ReLU(),nn.MaxPool2d(2,2))\n",
        "        self.conv3 = nn.Sequential(nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding='same'),nn.ReLU(),nn.MaxPool2d(2,2))\n",
        "        self.conv4 = nn.Sequential(nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding='same'),nn.ReLU(),nn.MaxPool2d(2,2))\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.CNN_outshape = self._get_conv_output(input_shape)\n",
        "        self.linear = nn.Linear(self.CNN_outshape, output_size)\n",
        "    def _get_conv_output(self, shape):\n",
        "        bs = 1\n",
        "        dummy_x = torch.empty(bs, *shape)\n",
        "        x = self._forward_features(dummy_x)\n",
        "        CNN_outshape = x.flatten(1).size(1)\n",
        "        return CNN_outshape\n",
        "    def _forward_features(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.flatten(x)\n",
        "        return x\n",
        "    def forward(self, x):\n",
        "        x = self._forward_features(x)\n",
        "        x = self.linear(x.flatten(1))\n",
        "        return x\n",
        "model = CNN().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2wfRyNwlz39"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop((image_size,image_size)),\n",
        "    transforms.RandomHorizontalFlip(p=0.4),\n",
        "    transforms.RandomVerticalFlip(p=0.4),\n",
        "    transforms.RandomRotation(degrees=[-7.5, 7.5])\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_1W1LWIB2Nv"
      },
      "outputs": [],
      "source": [
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay= 0.005)\n",
        "\n",
        "def train(train_loader): #Training\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "    correct = 0\n",
        "    total = len(train_loader.dataset)\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        #data augumentation\n",
        "        #images = transform(images)\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        predicted = outputs.max(1, keepdim=True)[1]\n",
        "        labels = labels.view_as(predicted)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "    train_acc = correct / total\n",
        "    return train_loss, train_acc\n",
        "\n",
        "def valid(test_loader): #Validation\n",
        "    model.eval()\n",
        "    running_loss = 0\n",
        "    correct = 0\n",
        "    total = len(test_loader.dataset)\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item()\n",
        "            predicted = outputs.max(1, keepdim=True)[1]\n",
        "            labels = labels.view_as(predicted)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "    val_loss = running_loss / len(test_loader)\n",
        "    val_acc = correct / total\n",
        "    return val_loss, val_acc\n",
        "\n",
        "#空配列\n",
        "acc_list = []\n",
        "loss_list = []\n",
        "val_loss_list = []\n",
        "val_acc_list = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_7--9MRHX-Lt"
      },
      "outputs": [],
      "source": [
        "nepoch = 300\n",
        "\n",
        "for epoch in range(nepoch):\n",
        "    loss, acc = train(train_dataloader)\n",
        "    val_loss, val_acc = valid(val_dataloader)\n",
        "    print('epoch %d, loss: %.4f acc: %.4f val_loss: %.4f val_acc: %.4f' % (epoch, loss,acc, val_loss, val_acc))\n",
        "    loss_list.append(loss)\n",
        "    acc_list.append(acc)\n",
        "    val_loss_list.append(val_loss)\n",
        "    val_acc_list.append(val_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XI4WwTyXX-Lu"
      },
      "outputs": [],
      "source": [
        "\n",
        "torch.save(model, 'model.pt')\n",
        "model = torch.load('model.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8sM7oJUATzd"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(f'正解率：{val_acc_list[-1] * 100:.2f} %')\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(2, 1, figsize=(8, 10))\n",
        "\n",
        "\n",
        "ax[0].plot(range(nepoch), loss_list, color='red', linestyle='-', label='train_loss')\n",
        "ax[0].plot(range(nepoch), val_loss_list, color='blue', linestyle='-', label='val_loss')\n",
        "ax[0].legend()\n",
        "ax[0].set_xlabel('エポック')\n",
        "ax[0].set_ylabel('損失')\n",
        "ax[0].set_title('学習と検証の損失曲線')\n",
        "\n",
        "\n",
        "ax[1].plot(range(nepoch), acc_list, color='blue', linestyle='-', label='acc')\n",
        "ax[1].plot(range(nepoch), val_acc_list, color='green', linestyle='-', label='val_acc')\n",
        "ax[1].legend()\n",
        "ax[1].set_xlabel('エポック')\n",
        "ax[1].set_ylabel('精度')\n",
        "ax[1].set_title('学習と検証の精度曲線')\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlqsNLwmDb-R"
      },
      "outputs": [],
      "source": [
        "\n",
        "def test_alternative(test_loader):\n",
        "    prob, pred, true = [], [], []\n",
        "    model.eval()\n",
        "    running_loss, correct = 0, 0\n",
        "    total = len(test_loader.dataset)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "\n",
        "            images, labels = map(lambda x: x.to(device), batch)\n",
        "\n",
        "\n",
        "            outputs = model(images)\n",
        "            lprob, predicted = torch.max(outputs, dim=1, keepdim=True)\n",
        "\n",
        "            labels = labels.view_as(predicted)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            prob.extend(scipy.special.expit(outputs[:, 1].cpu().numpy()))\n",
        "            pred.extend(predicted.cpu().numpy())\n",
        "            true.extend(labels.cpu().numpy())\n",
        "\n",
        "    return prob, pred, true\n",
        "\n",
        "\n",
        "prob, pred, true = test_alternative(test_dataloader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAuiwaHzIEu8"
      },
      "outputs": [],
      "source": [
        "\n",
        "plt.figure(figsize = (25, 25))\n",
        "for i in range(20):\n",
        "    plt.subplot(5, 4, i + 1)\n",
        "    plt.axis(\"off\")\n",
        "    if pred[i] == true[i]:\n",
        "        plt.title(\"pred:\"+str(pred[i].astype(np.uint8))+' - '+\"true:\"+str(true[i].astype(np.uint8))+'\\n'+'Prob.(Y=1) = %.4f' % (prob[i]))\n",
        "    else:\n",
        "        plt.title(\"pred:\"+str(pred[i].astype(np.uint8))+' - '+\"true:\"+str(true[i].astype(np.uint8))+'\\n'+'Prob.(Y=1) = %.4f' % (prob[i]), color = \"red\") # 分類が間違っていた場合，赤字で書き込む\n",
        "\n",
        "    tmp = test_x[i][0].to('cpu').detach().numpy().copy()\n",
        "    tmp = tmp.transpose(1, 2, 0)\n",
        "    img_pil = Image.fromarray((tmp*255).astype(np.uint8))\n",
        "    plt.imshow(img_pil)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YXpTUm7JIGRn"
      },
      "outputs": [],
      "source": [
        "\n",
        "cmat = confusion_matrix(true, pred)\n",
        "print(cmat)\n",
        "\n",
        "tn, fp, fn, tp = cmat.flatten()\n",
        "\n",
        "acc = round((tp+tn)/(tp+tn+fp+fn),4)\n",
        "sen = round(tp/(tp+fn),4)\n",
        "spe = round(tn/(tn+fp),4)\n",
        "ppv = round(tp/(tp+fp),4)\n",
        "npv = round(tn/(tn+fn),4)\n",
        "print(\"acc=\",acc,\"sen=\",sen,\" ,spe=\",spe,\" ,ppv=\",ppv,\" ,npv=\",npv)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}